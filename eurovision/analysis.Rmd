---
title: "kendallkernel - cluster (multivariate) partial rankings"
author: "Yunlong Jiao"
date: "16 Sep 2015"
output: html_document
---

```{r setup, eval = TRUE, message = FALSE}
knitr::opts_chunk$set(error = FALSE, warning = FALSE, fig.width = 15, fig.height = 12, dev = "pdf", fig.keep = "high", fig.path = "figure/", cache.path = "cache/")
set.seed(94151402)

# utiles
library(kernrank) # fast kendall kernel
library(combinat)
library(reshape2)
library(ggplot2)
library(parallel)

# clustering
library(kernlab)
library(Rankcluster)
library(cluster)
source("kkmeans.R") # complementary functions for kernel kmeans for top-k rankings
```

## Multivariate partial rankings

Each instance $x=(x^1,\dots,x^p)$ is represented by a multivariate rank in which $x^j=(x^{j1},\dots,x^{jm_j})$ for $1\leq j \leq p$ is a (partial) rank of $m_j$ items. For example, foot index $j$ should indicate the ranking preference of the same customer over several years or on several incomparable item sets, in which case we would like to exploit information in parallel when performing clustering. The `Rankcluster::eurovision` data is a typical example of such data.

```{r mpr, cache = TRUE}
# load data - eurovision song contest data
data(eurovision)
dat <- eurovision$data
countries <- rownames(dat)
nrow(dat) # number of countries
dimsize <- eurovision$m
dimsize # dimension of multivariate partial rankings listed in format c(m_1,m_2,...,m_p)

# number of clusters
klist <- 2:6
```

- **Mixture of multivariate isr** Implemented by `Rankcluster::rankclust` with mostly defaulted parameters (except repeat times), see [Jacques and Biernacki (2014)](https://hal.inria.fr/hal-00743384/). This mixture model is originally derived to deal with heterogeneous multivariate (partial) ranks via modeling the voting process using ISR model. NOTE parameter setting is inherited from Section 4 _Numerical experiments_ of the paper but repeated `run` times.

```{r mpr_rankcluster, cache = TRUE}
key <- "mpr_rankcluster"

# set param
RjSE <- RjM <- rep(10, length(dimsize))
Qsem <- Ql <- 100
Bsem <- Bl <- 10
maxTry <- 20
run <- 10

# get clustering results
ptm <- proc.time()
set.seed(94121899)
assign(key, 
       rankclust(data = dat, m = dimsize, K = klist, criterion = "bic", 
                 Qsem = Qsem, Bsem = Bsem, RjSE = RjSE, RjM = RjM, Ql = Ql, Bl = Bl,
                 maxTry = maxTry, run = run))
proc.time() - ptm
```

```{r mpr_rankcluster_analysis}
# get clustering statistics
clstats_best <- lapply(seq(length(get(key)@K)), function(i){
  data.frame(nclust = get(key)@K[i], 
             loglike = get(key)@results[[i]]@ll, 
             bic = -(get(key)@results[[i]]@bic), 
             icl = -(get(key)@results[[i]]@icl))
})
clstats_best <- do.call("rbind", clstats_best)
clstats_best$nclust <- ordered(clstats_best$nclust)

# loglike (higher is better)
ggplot(clstats_best, aes(x = nclust, y = loglike)) + 
  geom_line(aes(group = 1)) + 
  geom_point(size = 3)

# bic (higher is better)
ggplot(clstats_best, aes(x = nclust, y = bic)) + 
  geom_line(aes(group = 1)) + 
  geom_point(size = 3)

# icl (higher is better)
ggplot(clstats_best, aes(x = nclust, y = icl)) + 
  geom_line(aes(group = 1)) + 
  geom_point(size = 3)

# estimated clustering by rankclust (nclust corresp to largest bic)
i_best <- which.max(clstats_best$bic)
cl_best <- get(key)@results[[i_best]]

# summary of clustering
cest <- cl_best@partition
table(cest)
split(countries, cest)
```

- **Kendall kernel kmeans** Implemented by `kernlab::kkmeans` with defaulted parameters where kernel similarity values are kendall kernel for partial rankings further averaged over multivariates present. Specificallly, this method is model-free where similarities of partial ranks are adopted by convolution Kendall kernel and multivariate information is utilized by a simple average of kernel values from variates in parallel (NOTE other multiple kernel learning approaches apply).

```{r mpr_kkmeans, cache = TRUE}
key <- "mpr_kkmeans"

# set param
nrepeats <- 100

# get clustering results
ptm <- proc.time()
kmatrix <- kernmat(dat = dat, dimsize = dimsize, kf = "kendall_top", procf = "procf_Rankcluster")
dmatrix <- distmat(kmatrix)
assign(key, kkmeans_multi(kmatrix = kmatrix, klist = klist, nrepeats = nrepeats, dmatrix = dmatrix, seed = 31286963))
proc.time() - ptm
```

```{r mpr_kkmeans_analysis}
# get clustering statistics
clstats <- kkmeans_stats(get(key))
clstats_best <- kkmeans_stats_best(clstats)

# distsum (lower is better)
ggplot() + 
    geom_boxplot(data = clstats, aes(x = nclust, y = distsum), alpha = 0.5) + 
    geom_line(data = clstats_best, aes(x = nclust, y = distsum, group = 1)) + 
    geom_point(data = clstats_best, aes(x = nclust, y = distsum), size = 3)

# silhouette (higher is better)
ggplot() + 
    geom_boxplot(data = clstats, aes(x = nclust, y = silhouette), alpha = 0.5) + 
    geom_line(data = clstats_best, aes(x = nclust, y = silhouette, group = 1)) + 
    geom_point(data = clstats_best, aes(x = nclust, y = silhouette), size = 3)

# estimated clustering by kkmeans (nclust corresp to highest silhouette)
i_best <- clstats_best[which.max(clstats_best$silhouette), ]
cl_best <- get(key)[[as.character(i_best$nclust)]][[i_best$rep]]

# summary of clustering
cest <- cl_best@.Data
table(cest)
split(countries, cest)

# silhouette plot for best fit
sil <- cluster::silhouette(x = cest, dmatrix = dmatrix)
rownames(sil) <- countries
par(font = 2, font.axis = 2, font.lab = 2, font.main = 2, font.sub = 2, 
    cex = 1.25, cex.axis = 1.25, cex.lab = 2, cex.main = 2, cex.sub = 2, 
    mar = c(4, 17, 0, 2) + 0.1)
c6 <- c("tomato", "light blue", "forest green", "purple2", "goldenrod4", "gray20")
plot.silhouette_modified(sil, max.strlen = max(nchar(countries)), col = c6[1:max(cest)], cex.names = 1.25,
                         do.n.k = FALSE, do.clus.stat = FALSE)
```

## session info

```{r session_info}
devtools::session_info()
```
